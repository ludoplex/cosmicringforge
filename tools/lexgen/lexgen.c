/* MBSE Stacks — Lexer Generator
 * Ring 0: Pure C, minimal bootstrap
 *
 * Generates table-driven lexers from token specifications.
 * Output is pure C with no runtime dependencies.
 *
 * TRUE DOGFOODING: Uses lexgen_self.h which expands lexgen_tokens.def
 * via X-macros to define this generator's own token types.
 *
 * Usage: lexgen <tokens.lex> [output_dir] [prefix]
 *
 * Token format (one per line):
 *   TOKEN_NAME   "literal"           # Exact match
 *   TOKEN_NAME   [regex]             # Pattern match
 *   TOKEN_NAME   [regex] @skip       # Skip this token (whitespace)
 */

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <ctype.h>
#include <stdint.h>
#include <time.h>
#include <errno.h>
#include <sys/stat.h>

/* ── Self-hosted tokens (dogfooding) ─────────────────────────────── */
#include "lexgen_self.h"

#define LEXGEN_VERSION "1.0.0"
#define MAX_LINE 1024
#define MAX_TOKENS 256
#define MAX_NAME 64
#define MAX_PATTERN 256
#define MAX_PATH 512

typedef enum {
    PATTERN_LITERAL,    /* Exact string match */
    PATTERN_CHARCLASS,  /* Character class [a-z] */
    PATTERN_REGEX,      /* Simple regex subset */
} pattern_type_t;

typedef struct {
    char name[MAX_NAME];
    char pattern[MAX_PATTERN];
    pattern_type_t type;
    int skip;           /* @skip directive */
    int priority;       /* Keywords before identifiers */
} token_def_t;

static token_def_t tokens[MAX_TOKENS];
static int token_count = 0;

/* ── Utilities ────────────────────────────────────────────────────── */

static void trim(char *s) {
    char *start = s;
    while (*start && isspace((unsigned char)*start)) start++;
    if (start != s) memmove(s, start, strlen(start) + 1);
    char *end = s + strlen(s) - 1;
    while (end > s && isspace((unsigned char)*end)) *end-- = '\0';
}

static void to_upper(char *s) {
    for (; *s; s++) *s = (char)toupper((unsigned char)*s);
}

/* ── Parser ───────────────────────────────────────────────────────── */

static int parse_token_line(const char *line) {
    if (token_count >= MAX_TOKENS) {
        fprintf(stderr, "Error: Too many tokens\n");
        return -1;
    }

    token_def_t *t = &tokens[token_count];
    memset(t, 0, sizeof(*t));

    /* Parse: NAME   "pattern" or NAME   [pattern] */
    char name[MAX_NAME];
    char rest[MAX_LINE];

    const char *p = line;
    while (*p && !isspace((unsigned char)*p)) p++;
    int name_len = (int)(p - line);
    if (name_len >= MAX_NAME) name_len = MAX_NAME - 1;
    strncpy(name, line, (size_t)name_len);
    name[name_len] = '\0';
    strncpy(t->name, name, MAX_NAME - 1);

    while (*p && isspace((unsigned char)*p)) p++;
    strncpy(rest, p, MAX_LINE - 1);
    trim(rest);

    /* Determine pattern type */
    if (rest[0] == '"') {
        /* Literal: "keyword" */
        t->type = PATTERN_LITERAL;
        char *end = strchr(rest + 1, '"');
        if (!end) {
            fprintf(stderr, "Error: Unterminated literal: %s\n", line);
            return -1;
        }
        int len = (int)(end - rest - 1);
        if (len >= MAX_PATTERN) len = MAX_PATTERN - 1;
        strncpy(t->pattern, rest + 1, (size_t)len);
        t->pattern[len] = '\0';
        t->priority = 10;  /* Keywords have high priority */
    } else if (rest[0] == '[') {
        /* Character class or regex */
        t->type = PATTERN_CHARCLASS;
        char *end = strchr(rest, ']');
        if (!end) {
            /* Multi-part pattern like [a-z][a-z0-9]* */
            strncpy(t->pattern, rest, MAX_PATTERN - 1);
            t->type = PATTERN_REGEX;
        } else {
            int len = (int)(end - rest + 1);
            if (len >= MAX_PATTERN) len = MAX_PATTERN - 1;
            strncpy(t->pattern, rest, (size_t)len);
            t->pattern[len] = '\0';
        }
        t->priority = 5;
    } else {
        /* Regex pattern */
        t->type = PATTERN_REGEX;
        char *space = strchr(rest, ' ');
        if (space) {
            int len = (int)(space - rest);
            strncpy(t->pattern, rest, (size_t)len);
            t->pattern[len] = '\0';
        } else {
            strncpy(t->pattern, rest, MAX_PATTERN - 1);
        }
        t->priority = 5;
    }

    /* Check for @skip directive */
    if (strstr(rest, "@skip")) {
        t->skip = 1;
    }

    token_count++;
    return 0;
}

static int parse_spec(const char *filename) {
    FILE *f = fopen(filename, "r");
    if (!f) {
        fprintf(stderr, "Error: Cannot open %s\n", filename);
        return -1;
    }

    char line[MAX_LINE];
    while (fgets(line, sizeof(line), f)) {
        trim(line);
        if (line[0] == '\0' || line[0] == '#') continue;
        if (parse_token_line(line) != 0) {
            fclose(f);
            return -1;
        }
    }

    fclose(f);
    return 0;
}

/* ── Code Generation ──────────────────────────────────────────────── */

static void generate_header(FILE *out, const char *guard) {
    fprintf(out, "/* AUTO-GENERATED by lexgen %s — DO NOT EDIT */\n", LEXGEN_VERSION);
    fprintf(out, "#ifndef %s\n", guard);
    fprintf(out, "#define %s\n\n", guard);
    fprintf(out, "#include <stddef.h>\n\n");
}

static int generate_lexer_h(const char *outdir, const char *prefix) {
    char path[MAX_PATH];
    char guard[128];
    char header_name[128];

    snprintf(header_name, sizeof(header_name), "%s_lexer.h", prefix);
    for (char *p = header_name; *p; p++) *p = (char)tolower((unsigned char)*p);

    snprintf(guard, sizeof(guard), "%s_LEXER_H", prefix);
    to_upper(guard);

    snprintf(path, sizeof(path), "%s/%s", outdir, header_name);
    FILE *out = fopen(path, "w");
    if (!out) {
        fprintf(stderr, "Error: Cannot create %s\n", path);
        return -1;
    }

    generate_header(out, guard);

    /* Token enum */
    fprintf(out, "typedef enum {\n");
    fprintf(out, "    %s_TOKEN_EOF = 0,\n", prefix);
    fprintf(out, "    %s_TOKEN_ERROR,\n", prefix);
    for (int i = 0; i < token_count; i++) {
        fprintf(out, "    %s_%s,\n", prefix, tokens[i].name);
    }
    fprintf(out, "    %s_TOKEN_COUNT\n", prefix);
    fprintf(out, "} %s_token_type_t;\n\n", prefix);

    /* Token structure */
    fprintf(out, "typedef struct {\n");
    fprintf(out, "    %s_token_type_t type;\n", prefix);
    fprintf(out, "    const char *start;\n");
    fprintf(out, "    size_t length;\n");
    fprintf(out, "    int line;\n");
    fprintf(out, "    int column;\n");
    fprintf(out, "} %s_token_t;\n\n", prefix);

    /* Lexer state */
    fprintf(out, "typedef struct {\n");
    fprintf(out, "    const char *source;\n");
    fprintf(out, "    const char *current;\n");
    fprintf(out, "    int line;\n");
    fprintf(out, "    int column;\n");
    fprintf(out, "} %s_lexer_t;\n\n", prefix);

    /* Function declarations */
    fprintf(out, "void %s_lexer_init(%s_lexer_t *lex, const char *source);\n", prefix, prefix);
    fprintf(out, "%s_token_t %s_lexer_next(%s_lexer_t *lex);\n", prefix, prefix, prefix);
    fprintf(out, "const char *%s_token_name(%s_token_type_t type);\n", prefix, prefix);
    fprintf(out, "\n");

    fprintf(out, "#endif /* %s */\n", guard);
    fclose(out);

    fprintf(stderr, "Generated %s\n", path);
    return 0;
}

static int generate_lexer_c(const char *outdir, const char *prefix) {
    char path[MAX_PATH];
    char header_name[128];
    char impl_name[128];

    snprintf(header_name, sizeof(header_name), "%s_lexer.h", prefix);
    for (char *p = header_name; *p; p++) *p = (char)tolower((unsigned char)*p);

    snprintf(impl_name, sizeof(impl_name), "%s_lexer.c", prefix);
    for (char *p = impl_name; *p; p++) *p = (char)tolower((unsigned char)*p);

    snprintf(path, sizeof(path), "%s/%s", outdir, impl_name);
    FILE *out = fopen(path, "w");
    if (!out) {
        fprintf(stderr, "Error: Cannot create %s\n", path);
        return -1;
    }

    fprintf(out, "/* AUTO-GENERATED by lexgen %s — DO NOT EDIT */\n\n", LEXGEN_VERSION);
    fprintf(out, "#include \"%s\"\n", header_name);
    fprintf(out, "#include <string.h>\n");
    fprintf(out, "#include <ctype.h>\n\n");

    /* Token name table */
    fprintf(out, "static const char *token_names[] = {\n");
    fprintf(out, "    \"EOF\",\n");
    fprintf(out, "    \"ERROR\",\n");
    for (int i = 0; i < token_count; i++) {
        fprintf(out, "    \"%s\",\n", tokens[i].name);
    }
    fprintf(out, "};\n\n");

    /* Keyword table for literals */
    fprintf(out, "typedef struct {\n");
    fprintf(out, "    const char *keyword;\n");
    fprintf(out, "    %s_token_type_t type;\n", prefix);
    fprintf(out, "} keyword_entry_t;\n\n");

    fprintf(out, "static const keyword_entry_t keywords[] = {\n");
    for (int i = 0; i < token_count; i++) {
        if (tokens[i].type == PATTERN_LITERAL) {
            fprintf(out, "    {\"%s\", %s_%s},\n", tokens[i].pattern, prefix, tokens[i].name);
        }
    }
    fprintf(out, "    {NULL, 0}\n");
    fprintf(out, "};\n\n");

    /* Init function */
    fprintf(out, "void %s_lexer_init(%s_lexer_t *lex, const char *source) {\n", prefix, prefix);
    fprintf(out, "    lex->source = source;\n");
    fprintf(out, "    lex->current = source;\n");
    fprintf(out, "    lex->line = 1;\n");
    fprintf(out, "    lex->column = 1;\n");
    fprintf(out, "}\n\n");

    /* Token name function */
    fprintf(out, "const char *%s_token_name(%s_token_type_t type) {\n", prefix, prefix);
    fprintf(out, "    if (type >= 0 && type < %s_TOKEN_COUNT) {\n", prefix);
    fprintf(out, "        return token_names[type];\n");
    fprintf(out, "    }\n");
    fprintf(out, "    return \"UNKNOWN\";\n");
    fprintf(out, "}\n\n");

    /* Simple lexer implementation */
    fprintf(out, "static int is_alpha(char c) { return isalpha((unsigned char)c) || c == '_'; }\n");
    fprintf(out, "static int is_alnum(char c) { return isalnum((unsigned char)c) || c == '_'; }\n");
    fprintf(out, "static int is_digit(char c) { return isdigit((unsigned char)c); }\n\n");

    fprintf(out, "%s_token_t %s_lexer_next(%s_lexer_t *lex) {\n", prefix, prefix, prefix);
    fprintf(out, "    %s_token_t tok;\n", prefix);
    fprintf(out, "    tok.line = lex->line;\n");
    fprintf(out, "    tok.column = lex->column;\n\n");

    fprintf(out, "    /* Skip whitespace */\n");
    fprintf(out, "    while (*lex->current && isspace((unsigned char)*lex->current)) {\n");
    fprintf(out, "        if (*lex->current == '\\n') { lex->line++; lex->column = 1; }\n");
    fprintf(out, "        else { lex->column++; }\n");
    fprintf(out, "        lex->current++;\n");
    fprintf(out, "    }\n\n");

    fprintf(out, "    tok.start = lex->current;\n");
    fprintf(out, "    tok.line = lex->line;\n");
    fprintf(out, "    tok.column = lex->column;\n\n");

    fprintf(out, "    if (*lex->current == '\\0') {\n");
    fprintf(out, "        tok.type = %s_TOKEN_EOF;\n", prefix);
    fprintf(out, "        tok.length = 0;\n");
    fprintf(out, "        return tok;\n");
    fprintf(out, "    }\n\n");

    fprintf(out, "    /* Check keywords first */\n");
    fprintf(out, "    for (const keyword_entry_t *kw = keywords; kw->keyword; kw++) {\n");
    fprintf(out, "        size_t len = strlen(kw->keyword);\n");
    fprintf(out, "        if (strncmp(lex->current, kw->keyword, len) == 0 &&\n");
    fprintf(out, "            !is_alnum(lex->current[len])) {\n");
    fprintf(out, "            tok.type = kw->type;\n");
    fprintf(out, "            tok.length = len;\n");
    fprintf(out, "            lex->current += len;\n");
    fprintf(out, "            lex->column += (int)len;\n");
    fprintf(out, "            return tok;\n");
    fprintf(out, "        }\n");
    fprintf(out, "    }\n\n");

    fprintf(out, "    /* Identifier */\n");
    fprintf(out, "    if (is_alpha(*lex->current)) {\n");
    fprintf(out, "        while (is_alnum(*lex->current)) {\n");
    fprintf(out, "            lex->current++;\n");
    fprintf(out, "            lex->column++;\n");
    fprintf(out, "        }\n");
    fprintf(out, "        tok.type = %s_TOKEN_ERROR; /* Replace with IDENT token */\n", prefix);
    fprintf(out, "        tok.length = (size_t)(lex->current - tok.start);\n");
    fprintf(out, "        return tok;\n");
    fprintf(out, "    }\n\n");

    fprintf(out, "    /* Number */\n");
    fprintf(out, "    if (is_digit(*lex->current)) {\n");
    fprintf(out, "        while (is_digit(*lex->current)) {\n");
    fprintf(out, "            lex->current++;\n");
    fprintf(out, "            lex->column++;\n");
    fprintf(out, "        }\n");
    fprintf(out, "        tok.type = %s_TOKEN_ERROR; /* Replace with NUMBER token */\n", prefix);
    fprintf(out, "        tok.length = (size_t)(lex->current - tok.start);\n");
    fprintf(out, "        return tok;\n");
    fprintf(out, "    }\n\n");

    fprintf(out, "    /* Unknown character */\n");
    fprintf(out, "    tok.type = %s_TOKEN_ERROR;\n", prefix);
    fprintf(out, "    tok.length = 1;\n");
    fprintf(out, "    lex->current++;\n");
    fprintf(out, "    lex->column++;\n");
    fprintf(out, "    return tok;\n");
    fprintf(out, "}\n");

    fclose(out);
    fprintf(stderr, "Generated %s\n", path);
    return 0;
}

static void generate_version(const char *outdir, const char *profile) {
    char path[MAX_PATH];
    snprintf(path, sizeof(path), "%s/GENERATOR_VERSION", outdir);

    FILE *out = fopen(path, "w");
    if (!out) return;

    time_t now = time(NULL);
    struct tm *t = gmtime(&now);
    fprintf(out, "lexgen %s\n", LEXGEN_VERSION);
    fprintf(out, "generated: %04d-%02d-%02dT%02d:%02d:%02dZ\n",
            t->tm_year + 1900, t->tm_mon + 1, t->tm_mday,
            t->tm_hour, t->tm_min, t->tm_sec);
    fprintf(out, "profile: %s\n", profile);
    fprintf(out, "tokens: %d\n", token_count);

    fclose(out);
}

static int ensure_output_dir(const char *outdir) {
    if (!outdir || !*outdir) return 0;
    if (mkdir(outdir, 0777) == 0 || errno == EEXIST) return 0;
    perror("mkdir");
    return -1;
}

/* ── Main ─────────────────────────────────────────────────────────── */

static void print_usage(void) {
    fprintf(stderr, "lexgen %s — Table-Driven Lexer Generator\n", LEXGEN_VERSION);
    fprintf(stderr, "\n");
    fprintf(stderr, "Usage: lexgen <tokens.lex> [output_dir] [prefix]\n");
    fprintf(stderr, "\n");
    fprintf(stderr, "Token format (one per line):\n");
    fprintf(stderr, "  TOKEN_NAME   \"literal\"       # Exact match (keywords)\n");
    fprintf(stderr, "  TOKEN_NAME   [a-z]+          # Pattern match\n");
    fprintf(stderr, "  TOKEN_NAME   pattern @skip   # Skip token (whitespace)\n");
    fprintf(stderr, "\n");
    fprintf(stderr, "Output:\n");
    fprintf(stderr, "  <prefix>_lexer.h  — Token enum and lexer API\n");
    fprintf(stderr, "  <prefix>_lexer.c  — Table-driven lexer\n");
}

int main(int argc, char *argv[]) {
    if (argc < 2) {
        print_usage();
        return 1;
    }

    const char *input = argv[1];
    const char *outdir = argc > 2 ? argv[2] : ".";
    const char *prefix = argc > 3 ? argv[3] : "MBSE";
    const char *profile = getenv("PROFILE");
    if (!profile) profile = "portable";

    if (parse_spec(input) != 0) {
        return 1;
    }

    fprintf(stderr, "Parsed %d tokens from %s\n", token_count, input);

    if (ensure_output_dir(outdir) != 0) {
        return 1;
    }

    if (generate_lexer_h(outdir, prefix) != 0) return 1;
    if (generate_lexer_c(outdir, prefix) != 0) return 1;

    generate_version(outdir, profile);

    return 0;
}
